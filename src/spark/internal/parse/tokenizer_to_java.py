#!/bin/env python
#*****************************************************************************#
#* Copyright (c) 2004-2008, SRI International.                               *#
#* All rights reserved.                                                      *#
#*                                                                           *#
#* Redistribution and use in source and binary forms, with or without        *#
#* modification, are permitted provided that the following conditions are    *#
#* met:                                                                      *#
#*   * Redistributions of source code must retain the above copyright        *#
#*     notice, this list of conditions and the following disclaimer.         *#
#*   * Redistributions in binary form must reproduce the above copyright     *#
#*     notice, this list of conditions and the following disclaimer in the   *#
#*     documentation and/or other materials provided with the distribution.  *#
#*   * Neither the name of SRI International nor the names of its            *#
#*     contributors may be used to endorse or promote products derived from  *#
#*     this software without specific prior written permission.              *#
#*                                                                           *#
#* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS       *#
#* "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT         *#
#* LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR     *#
#* A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT      *#
#* OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,     *#
#* SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT          *#
#* LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,     *#
#* DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY     *#
#* THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT       *#
#* (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE     *#
#* OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.      *#
#*****************************************************************************#
#* "$Revision:: 128                                                       $" *#
#* "$HeadURL:: https://svn.ai.sri.com/projects/spark/trunk/spark/src/spar#$" *#
#*****************************************************************************#
"""
Run this command from the directory this file resides in.

python tokenizer_to_java.py

"""

import sys
sys.path.append("../../..")

from spark.internal.parse.generic_tokenizer import _C, _N, _E
from spark.internal.parse.sparkl_tokenizer_source import Token, SPARKLFSMTABLE


def openWriteFile(name):
    offset = "../../../com/sri/ai/jspark/parse/"
    filename = offset + name
    print "Writing", filename
    return open(filename, 'w')

def tokenizerTableToJava(table):
    tokens = []
    f = open("tokenizer_to_java.header.tmpl.txt", 'r')
    header_tmpl = f.read()
    f.close()

    f = open("tokenizer_to_java.IntTableTokenStream.tmpl.txt", 'r')
    itts_tmpl = f.read()
    f.close()

    f = open("tokenizer_to_java.util.tmpl.txt", 'r')
    util_tmpl = f.read()
    f.close()

    f = openWriteFile("AutoTableTokenStream.java")
    f.write(header_tmpl)
    f.write(itts_tmpl)    
    f.write("\n\n    static final short[][] table = {\n")
    for actions in table:
        f.write("        {\n")
        for (act, next) in actions:
            actletter = ''
            if act == _C:
                actletter = 'C'
            elif act == _N:
                actletter = 'N'
                if next not in tokens:
                    tokens.append(next)
                next = next._name
            elif act == _E:
                actletter = 'E'
                if next not in tokens:
                    tokens.append(next)
                next = next._name                
            else:
                raise Error("Unrecognized state for translation"+act)
            f.write("             %s|%s, \n"%(actletter, next))
        f.write("        }, \n")
    f.write("    };\n") #end of table
    f.write("}\n") # end AutoTableTokenStream
    f.close()
    
    #our int table cannot handle characters outside the 256 range
    tokens.append(Token("ILLEGAL_CHAR", "non-ascii character"))

    f = openWriteFile("AutoTableTokens.java")
    f.write(header_tmpl)    
    f.write("/**\n"+
            " * auto-generated by tokenizer_to_java.py\n"+
            " * @see AutoTableTokenStream\n"+            
            " */\n"+           
            "public interface AutoTableTokens {\n\n")
    counter = 1
    for tok in tokens:
        f.write("    public static final short %s = %s;\n"%(tok._name, counter))
        counter = counter + 1
    f.write("\n}\n") # end AutoTableTokens
    f.close()

    f = openWriteFile("AutoTableTokensUtil.java")
    f.write(header_tmpl)    
    f.write(util_tmpl)
    f.write("\n    /**"+
            "\n      * @return a string name for the token"+
            "\n      */"+
            "\n    public static String tokenName(short token) {\n")
    f.write("        switch (token) {\n")
    for tok in tokens:
        f.write('        case %s: return "%s";\n'%(tok._name, tok._name))
    f.write('        default: return "UNKNOWN";\n')
    f.write("        }\n"+
            "    }\n")
    f.write("\n    /**"+
            "\n      * @return a brief string describing the token"+
            "\n      */"+
            "\n    public static String tokenDescription(short token) {"+
            "\n        switch (token) {\n")
    for tok in tokens:
        f.write('        case %s: return "%s";\n'%(tok._name, tok.getText()))
    f.write('        default: return "UNKNOWN";\n')
    f.write("        }\n"+
            "    }\n"+
            "}\n")
    f.close()
    
    # the following does not need to be emitted. i only
    # reproduce it here for completeness as the rest of
    # what's emitted presumes its existence
    
    #package com.ai.sri.spark.engine.parse;
    #
    #public interface AutoTableTokenSymbols {
    #    public static final short C = 1;
    #    public static final short N = 2;
    #    public static final short E = 3;
    #    public static final short ACTION_TYPE_MASK = 0xF00;
    #    public static final short ACTION_ARG_MASK = 0x0FF;
    #    public static final short NUMCHARS = 256; 
    #    public static final short EOF_NUM = NUMCHARS;
    #}

tokenizerTableToJava(SPARKLFSMTABLE)
